{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import autograd\n",
    "from torch.utils import data\n",
    "from torch.optim import Adam\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 난수 생성기가 항상 일정한 값을 출력하게 하기 위해 seed 고정\n",
    "random_seed = 2021\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join('/USER/traffic/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>시간</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>140</th>\n",
       "      <th>150</th>\n",
       "      <th>160</th>\n",
       "      <th>...</th>\n",
       "      <th>1020</th>\n",
       "      <th>1040</th>\n",
       "      <th>1100</th>\n",
       "      <th>1200</th>\n",
       "      <th>1510</th>\n",
       "      <th>2510</th>\n",
       "      <th>3000</th>\n",
       "      <th>4510</th>\n",
       "      <th>5510</th>\n",
       "      <th>6000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200101</td>\n",
       "      <td>0</td>\n",
       "      <td>83247</td>\n",
       "      <td>19128</td>\n",
       "      <td>2611</td>\n",
       "      <td>5161</td>\n",
       "      <td>1588</td>\n",
       "      <td>892</td>\n",
       "      <td>32263</td>\n",
       "      <td>1636</td>\n",
       "      <td>...</td>\n",
       "      <td>1311</td>\n",
       "      <td>3482</td>\n",
       "      <td>11299</td>\n",
       "      <td>7072</td>\n",
       "      <td>1176</td>\n",
       "      <td>3810</td>\n",
       "      <td>748</td>\n",
       "      <td>3920</td>\n",
       "      <td>2133</td>\n",
       "      <td>3799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20200101</td>\n",
       "      <td>1</td>\n",
       "      <td>89309</td>\n",
       "      <td>19027</td>\n",
       "      <td>3337</td>\n",
       "      <td>5502</td>\n",
       "      <td>1650</td>\n",
       "      <td>1043</td>\n",
       "      <td>35609</td>\n",
       "      <td>1644</td>\n",
       "      <td>...</td>\n",
       "      <td>1162</td>\n",
       "      <td>3849</td>\n",
       "      <td>13180</td>\n",
       "      <td>8771</td>\n",
       "      <td>1283</td>\n",
       "      <td>3763</td>\n",
       "      <td>782</td>\n",
       "      <td>3483</td>\n",
       "      <td>2057</td>\n",
       "      <td>4010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20200101</td>\n",
       "      <td>2</td>\n",
       "      <td>66611</td>\n",
       "      <td>14710</td>\n",
       "      <td>2970</td>\n",
       "      <td>4631</td>\n",
       "      <td>1044</td>\n",
       "      <td>921</td>\n",
       "      <td>26821</td>\n",
       "      <td>1104</td>\n",
       "      <td>...</td>\n",
       "      <td>768</td>\n",
       "      <td>2299</td>\n",
       "      <td>7986</td>\n",
       "      <td>5426</td>\n",
       "      <td>1536</td>\n",
       "      <td>3229</td>\n",
       "      <td>491</td>\n",
       "      <td>2634</td>\n",
       "      <td>1526</td>\n",
       "      <td>3388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20200101</td>\n",
       "      <td>3</td>\n",
       "      <td>53290</td>\n",
       "      <td>13753</td>\n",
       "      <td>2270</td>\n",
       "      <td>4242</td>\n",
       "      <td>1021</td>\n",
       "      <td>790</td>\n",
       "      <td>21322</td>\n",
       "      <td>909</td>\n",
       "      <td>...</td>\n",
       "      <td>632</td>\n",
       "      <td>1716</td>\n",
       "      <td>5703</td>\n",
       "      <td>3156</td>\n",
       "      <td>1104</td>\n",
       "      <td>2882</td>\n",
       "      <td>431</td>\n",
       "      <td>2488</td>\n",
       "      <td>1268</td>\n",
       "      <td>3686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20200101</td>\n",
       "      <td>4</td>\n",
       "      <td>52095</td>\n",
       "      <td>17615</td>\n",
       "      <td>2406</td>\n",
       "      <td>3689</td>\n",
       "      <td>1840</td>\n",
       "      <td>922</td>\n",
       "      <td>22711</td>\n",
       "      <td>1354</td>\n",
       "      <td>...</td>\n",
       "      <td>875</td>\n",
       "      <td>2421</td>\n",
       "      <td>5816</td>\n",
       "      <td>2933</td>\n",
       "      <td>1206</td>\n",
       "      <td>2433</td>\n",
       "      <td>499</td>\n",
       "      <td>2952</td>\n",
       "      <td>1927</td>\n",
       "      <td>5608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>20200517</td>\n",
       "      <td>19</td>\n",
       "      <td>311727</td>\n",
       "      <td>101285</td>\n",
       "      <td>10085</td>\n",
       "      <td>30637</td>\n",
       "      <td>10060</td>\n",
       "      <td>8749</td>\n",
       "      <td>148935</td>\n",
       "      <td>6801</td>\n",
       "      <td>...</td>\n",
       "      <td>6726</td>\n",
       "      <td>15431</td>\n",
       "      <td>25597</td>\n",
       "      <td>14292</td>\n",
       "      <td>9300</td>\n",
       "      <td>22238</td>\n",
       "      <td>3786</td>\n",
       "      <td>16936</td>\n",
       "      <td>10729</td>\n",
       "      <td>20194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>20200517</td>\n",
       "      <td>20</td>\n",
       "      <td>305354</td>\n",
       "      <td>91426</td>\n",
       "      <td>8607</td>\n",
       "      <td>26021</td>\n",
       "      <td>8095</td>\n",
       "      <td>7198</td>\n",
       "      <td>136503</td>\n",
       "      <td>6147</td>\n",
       "      <td>...</td>\n",
       "      <td>5501</td>\n",
       "      <td>15378</td>\n",
       "      <td>24661</td>\n",
       "      <td>14747</td>\n",
       "      <td>8239</td>\n",
       "      <td>20604</td>\n",
       "      <td>3203</td>\n",
       "      <td>15018</td>\n",
       "      <td>9767</td>\n",
       "      <td>17962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3276</th>\n",
       "      <td>20200517</td>\n",
       "      <td>21</td>\n",
       "      <td>306008</td>\n",
       "      <td>75113</td>\n",
       "      <td>6325</td>\n",
       "      <td>19933</td>\n",
       "      <td>5711</td>\n",
       "      <td>4494</td>\n",
       "      <td>129412</td>\n",
       "      <td>5134</td>\n",
       "      <td>...</td>\n",
       "      <td>4216</td>\n",
       "      <td>12558</td>\n",
       "      <td>22781</td>\n",
       "      <td>14081</td>\n",
       "      <td>6392</td>\n",
       "      <td>17937</td>\n",
       "      <td>2447</td>\n",
       "      <td>12403</td>\n",
       "      <td>7825</td>\n",
       "      <td>14031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3277</th>\n",
       "      <td>20200517</td>\n",
       "      <td>22</td>\n",
       "      <td>237447</td>\n",
       "      <td>49498</td>\n",
       "      <td>4209</td>\n",
       "      <td>12145</td>\n",
       "      <td>3891</td>\n",
       "      <td>2718</td>\n",
       "      <td>96698</td>\n",
       "      <td>3526</td>\n",
       "      <td>...</td>\n",
       "      <td>2578</td>\n",
       "      <td>8870</td>\n",
       "      <td>16640</td>\n",
       "      <td>11066</td>\n",
       "      <td>4427</td>\n",
       "      <td>11955</td>\n",
       "      <td>1495</td>\n",
       "      <td>7507</td>\n",
       "      <td>5387</td>\n",
       "      <td>8889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3278</th>\n",
       "      <td>20200517</td>\n",
       "      <td>23</td>\n",
       "      <td>150312</td>\n",
       "      <td>27410</td>\n",
       "      <td>2350</td>\n",
       "      <td>6406</td>\n",
       "      <td>1803</td>\n",
       "      <td>1614</td>\n",
       "      <td>55788</td>\n",
       "      <td>1849</td>\n",
       "      <td>...</td>\n",
       "      <td>1377</td>\n",
       "      <td>5021</td>\n",
       "      <td>10058</td>\n",
       "      <td>7139</td>\n",
       "      <td>2250</td>\n",
       "      <td>6844</td>\n",
       "      <td>735</td>\n",
       "      <td>4116</td>\n",
       "      <td>3046</td>\n",
       "      <td>4606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3279 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            날짜  시간      10     100    101    120    121   140     150   160  \\\n",
       "0     20200101   0   83247   19128   2611   5161   1588   892   32263  1636   \n",
       "1     20200101   1   89309   19027   3337   5502   1650  1043   35609  1644   \n",
       "2     20200101   2   66611   14710   2970   4631   1044   921   26821  1104   \n",
       "3     20200101   3   53290   13753   2270   4242   1021   790   21322   909   \n",
       "4     20200101   4   52095   17615   2406   3689   1840   922   22711  1354   \n",
       "...        ...  ..     ...     ...    ...    ...    ...   ...     ...   ...   \n",
       "3274  20200517  19  311727  101285  10085  30637  10060  8749  148935  6801   \n",
       "3275  20200517  20  305354   91426   8607  26021   8095  7198  136503  6147   \n",
       "3276  20200517  21  306008   75113   6325  19933   5711  4494  129412  5134   \n",
       "3277  20200517  22  237447   49498   4209  12145   3891  2718   96698  3526   \n",
       "3278  20200517  23  150312   27410   2350   6406   1803  1614   55788  1849   \n",
       "\n",
       "      ...  1020   1040   1100   1200  1510   2510  3000   4510   5510   6000  \n",
       "0     ...  1311   3482  11299   7072  1176   3810   748   3920   2133   3799  \n",
       "1     ...  1162   3849  13180   8771  1283   3763   782   3483   2057   4010  \n",
       "2     ...   768   2299   7986   5426  1536   3229   491   2634   1526   3388  \n",
       "3     ...   632   1716   5703   3156  1104   2882   431   2488   1268   3686  \n",
       "4     ...   875   2421   5816   2933  1206   2433   499   2952   1927   5608  \n",
       "...   ...   ...    ...    ...    ...   ...    ...   ...    ...    ...    ...  \n",
       "3274  ...  6726  15431  25597  14292  9300  22238  3786  16936  10729  20194  \n",
       "3275  ...  5501  15378  24661  14747  8239  20604  3203  15018   9767  17962  \n",
       "3276  ...  4216  12558  22781  14081  6392  17937  2447  12403   7825  14031  \n",
       "3277  ...  2578   8870  16640  11066  4427  11955  1495   7507   5387   8889  \n",
       "3278  ...  1377   5021  10058   7139  2250   6844   735   4116   3046   4606  \n",
       "\n",
       "[3279 rows x 37 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(os.path.join(DATASET_PATH, 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>시간</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>140</th>\n",
       "      <th>150</th>\n",
       "      <th>160</th>\n",
       "      <th>...</th>\n",
       "      <th>1020</th>\n",
       "      <th>1040</th>\n",
       "      <th>1100</th>\n",
       "      <th>1200</th>\n",
       "      <th>1510</th>\n",
       "      <th>2510</th>\n",
       "      <th>3000</th>\n",
       "      <th>4510</th>\n",
       "      <th>5510</th>\n",
       "      <th>6000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200511</td>\n",
       "      <td>0</td>\n",
       "      <td>77968</td>\n",
       "      <td>14429</td>\n",
       "      <td>1233</td>\n",
       "      <td>4021</td>\n",
       "      <td>981</td>\n",
       "      <td>881</td>\n",
       "      <td>28672</td>\n",
       "      <td>1064</td>\n",
       "      <td>...</td>\n",
       "      <td>637</td>\n",
       "      <td>2604</td>\n",
       "      <td>5239</td>\n",
       "      <td>4168</td>\n",
       "      <td>1155</td>\n",
       "      <td>3596</td>\n",
       "      <td>337</td>\n",
       "      <td>2262</td>\n",
       "      <td>1608</td>\n",
       "      <td>2337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20200511</td>\n",
       "      <td>1</td>\n",
       "      <td>48679</td>\n",
       "      <td>9136</td>\n",
       "      <td>823</td>\n",
       "      <td>2618</td>\n",
       "      <td>654</td>\n",
       "      <td>572</td>\n",
       "      <td>17722</td>\n",
       "      <td>672</td>\n",
       "      <td>...</td>\n",
       "      <td>353</td>\n",
       "      <td>1870</td>\n",
       "      <td>3359</td>\n",
       "      <td>2558</td>\n",
       "      <td>1002</td>\n",
       "      <td>2157</td>\n",
       "      <td>257</td>\n",
       "      <td>1425</td>\n",
       "      <td>1018</td>\n",
       "      <td>1810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20200511</td>\n",
       "      <td>2</td>\n",
       "      <td>33773</td>\n",
       "      <td>8199</td>\n",
       "      <td>578</td>\n",
       "      <td>2188</td>\n",
       "      <td>392</td>\n",
       "      <td>502</td>\n",
       "      <td>14464</td>\n",
       "      <td>579</td>\n",
       "      <td>...</td>\n",
       "      <td>345</td>\n",
       "      <td>1499</td>\n",
       "      <td>2646</td>\n",
       "      <td>2022</td>\n",
       "      <td>876</td>\n",
       "      <td>1959</td>\n",
       "      <td>232</td>\n",
       "      <td>1155</td>\n",
       "      <td>927</td>\n",
       "      <td>1530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20200511</td>\n",
       "      <td>3</td>\n",
       "      <td>41511</td>\n",
       "      <td>9986</td>\n",
       "      <td>726</td>\n",
       "      <td>2817</td>\n",
       "      <td>555</td>\n",
       "      <td>646</td>\n",
       "      <td>17793</td>\n",
       "      <td>650</td>\n",
       "      <td>...</td>\n",
       "      <td>390</td>\n",
       "      <td>1730</td>\n",
       "      <td>3398</td>\n",
       "      <td>1967</td>\n",
       "      <td>912</td>\n",
       "      <td>2462</td>\n",
       "      <td>281</td>\n",
       "      <td>1477</td>\n",
       "      <td>959</td>\n",
       "      <td>1882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20200511</td>\n",
       "      <td>4</td>\n",
       "      <td>78680</td>\n",
       "      <td>19509</td>\n",
       "      <td>1463</td>\n",
       "      <td>4720</td>\n",
       "      <td>825</td>\n",
       "      <td>1088</td>\n",
       "      <td>35125</td>\n",
       "      <td>997</td>\n",
       "      <td>...</td>\n",
       "      <td>679</td>\n",
       "      <td>2958</td>\n",
       "      <td>7369</td>\n",
       "      <td>4120</td>\n",
       "      <td>1569</td>\n",
       "      <td>4568</td>\n",
       "      <td>577</td>\n",
       "      <td>3155</td>\n",
       "      <td>1871</td>\n",
       "      <td>3656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>20200524</td>\n",
       "      <td>19</td>\n",
       "      <td>314226</td>\n",
       "      <td>98345</td>\n",
       "      <td>10625</td>\n",
       "      <td>28618</td>\n",
       "      <td>8316</td>\n",
       "      <td>6684</td>\n",
       "      <td>141675</td>\n",
       "      <td>6619</td>\n",
       "      <td>...</td>\n",
       "      <td>8254</td>\n",
       "      <td>16118</td>\n",
       "      <td>23304</td>\n",
       "      <td>14082</td>\n",
       "      <td>8447</td>\n",
       "      <td>21694</td>\n",
       "      <td>2180</td>\n",
       "      <td>15746</td>\n",
       "      <td>10903</td>\n",
       "      <td>21014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>20200524</td>\n",
       "      <td>20</td>\n",
       "      <td>300001</td>\n",
       "      <td>87871</td>\n",
       "      <td>8226</td>\n",
       "      <td>22706</td>\n",
       "      <td>6981</td>\n",
       "      <td>5743</td>\n",
       "      <td>142933</td>\n",
       "      <td>6295</td>\n",
       "      <td>...</td>\n",
       "      <td>5225</td>\n",
       "      <td>15297</td>\n",
       "      <td>21919</td>\n",
       "      <td>14526</td>\n",
       "      <td>7332</td>\n",
       "      <td>19732</td>\n",
       "      <td>1990</td>\n",
       "      <td>14096</td>\n",
       "      <td>10028</td>\n",
       "      <td>17787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>20200524</td>\n",
       "      <td>21</td>\n",
       "      <td>304150</td>\n",
       "      <td>71126</td>\n",
       "      <td>6002</td>\n",
       "      <td>18317</td>\n",
       "      <td>4939</td>\n",
       "      <td>3779</td>\n",
       "      <td>133110</td>\n",
       "      <td>4781</td>\n",
       "      <td>...</td>\n",
       "      <td>4072</td>\n",
       "      <td>12685</td>\n",
       "      <td>21135</td>\n",
       "      <td>14403</td>\n",
       "      <td>5443</td>\n",
       "      <td>16967</td>\n",
       "      <td>1359</td>\n",
       "      <td>11670</td>\n",
       "      <td>7963</td>\n",
       "      <td>14041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>20200524</td>\n",
       "      <td>22</td>\n",
       "      <td>236751</td>\n",
       "      <td>44947</td>\n",
       "      <td>3575</td>\n",
       "      <td>11455</td>\n",
       "      <td>3135</td>\n",
       "      <td>2536</td>\n",
       "      <td>98582</td>\n",
       "      <td>3267</td>\n",
       "      <td>...</td>\n",
       "      <td>2489</td>\n",
       "      <td>8093</td>\n",
       "      <td>14427</td>\n",
       "      <td>10914</td>\n",
       "      <td>3861</td>\n",
       "      <td>11397</td>\n",
       "      <td>859</td>\n",
       "      <td>7270</td>\n",
       "      <td>5194</td>\n",
       "      <td>8230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>20200524</td>\n",
       "      <td>23</td>\n",
       "      <td>143609</td>\n",
       "      <td>26137</td>\n",
       "      <td>2242</td>\n",
       "      <td>6166</td>\n",
       "      <td>1609</td>\n",
       "      <td>1391</td>\n",
       "      <td>54633</td>\n",
       "      <td>1899</td>\n",
       "      <td>...</td>\n",
       "      <td>1343</td>\n",
       "      <td>4686</td>\n",
       "      <td>8732</td>\n",
       "      <td>6986</td>\n",
       "      <td>2161</td>\n",
       "      <td>6487</td>\n",
       "      <td>410</td>\n",
       "      <td>3963</td>\n",
       "      <td>2686</td>\n",
       "      <td>4690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>336 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           날짜  시간      10    100    101    120   121   140     150   160  ...  \\\n",
       "0    20200511   0   77968  14429   1233   4021   981   881   28672  1064  ...   \n",
       "1    20200511   1   48679   9136    823   2618   654   572   17722   672  ...   \n",
       "2    20200511   2   33773   8199    578   2188   392   502   14464   579  ...   \n",
       "3    20200511   3   41511   9986    726   2817   555   646   17793   650  ...   \n",
       "4    20200511   4   78680  19509   1463   4720   825  1088   35125   997  ...   \n",
       "..        ...  ..     ...    ...    ...    ...   ...   ...     ...   ...  ...   \n",
       "331  20200524  19  314226  98345  10625  28618  8316  6684  141675  6619  ...   \n",
       "332  20200524  20  300001  87871   8226  22706  6981  5743  142933  6295  ...   \n",
       "333  20200524  21  304150  71126   6002  18317  4939  3779  133110  4781  ...   \n",
       "334  20200524  22  236751  44947   3575  11455  3135  2536   98582  3267  ...   \n",
       "335  20200524  23  143609  26137   2242   6166  1609  1391   54633  1899  ...   \n",
       "\n",
       "     1020   1040   1100   1200  1510   2510  3000   4510   5510   6000  \n",
       "0     637   2604   5239   4168  1155   3596   337   2262   1608   2337  \n",
       "1     353   1870   3359   2558  1002   2157   257   1425   1018   1810  \n",
       "2     345   1499   2646   2022   876   1959   232   1155    927   1530  \n",
       "3     390   1730   3398   1967   912   2462   281   1477    959   1882  \n",
       "4     679   2958   7369   4120  1569   4568   577   3155   1871   3656  \n",
       "..    ...    ...    ...    ...   ...    ...   ...    ...    ...    ...  \n",
       "331  8254  16118  23304  14082  8447  21694  2180  15746  10903  21014  \n",
       "332  5225  15297  21919  14526  7332  19732  1990  14096  10028  17787  \n",
       "333  4072  12685  21135  14403  5443  16967  1359  11670   7963  14041  \n",
       "334  2489   8093  14427  10914  3861  11397   859   7270   5194   8230  \n",
       "335  1343   4686   8732   6986  2161   6487   410   3963   2686   4690  \n",
       "\n",
       "[336 rows x 37 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(os.path.join(DATASET_PATH, 'validate.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>시간</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>140</th>\n",
       "      <th>150</th>\n",
       "      <th>160</th>\n",
       "      <th>...</th>\n",
       "      <th>1020</th>\n",
       "      <th>1040</th>\n",
       "      <th>1100</th>\n",
       "      <th>1200</th>\n",
       "      <th>1510</th>\n",
       "      <th>2510</th>\n",
       "      <th>3000</th>\n",
       "      <th>4510</th>\n",
       "      <th>5510</th>\n",
       "      <th>6000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200518</td>\n",
       "      <td>0</td>\n",
       "      <td>82065</td>\n",
       "      <td>15172</td>\n",
       "      <td>1500</td>\n",
       "      <td>3294</td>\n",
       "      <td>1086</td>\n",
       "      <td>962</td>\n",
       "      <td>28931</td>\n",
       "      <td>1103</td>\n",
       "      <td>...</td>\n",
       "      <td>618</td>\n",
       "      <td>2790</td>\n",
       "      <td>5147</td>\n",
       "      <td>4331</td>\n",
       "      <td>1329</td>\n",
       "      <td>3665</td>\n",
       "      <td>404</td>\n",
       "      <td>2242</td>\n",
       "      <td>1619</td>\n",
       "      <td>2314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20200518</td>\n",
       "      <td>1</td>\n",
       "      <td>51248</td>\n",
       "      <td>9840</td>\n",
       "      <td>813</td>\n",
       "      <td>2356</td>\n",
       "      <td>696</td>\n",
       "      <td>546</td>\n",
       "      <td>17888</td>\n",
       "      <td>720</td>\n",
       "      <td>...</td>\n",
       "      <td>430</td>\n",
       "      <td>1864</td>\n",
       "      <td>3269</td>\n",
       "      <td>2561</td>\n",
       "      <td>921</td>\n",
       "      <td>2081</td>\n",
       "      <td>272</td>\n",
       "      <td>1390</td>\n",
       "      <td>1003</td>\n",
       "      <td>1766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20200518</td>\n",
       "      <td>2</td>\n",
       "      <td>39026</td>\n",
       "      <td>7894</td>\n",
       "      <td>760</td>\n",
       "      <td>2413</td>\n",
       "      <td>408</td>\n",
       "      <td>549</td>\n",
       "      <td>13357</td>\n",
       "      <td>498</td>\n",
       "      <td>...</td>\n",
       "      <td>322</td>\n",
       "      <td>1313</td>\n",
       "      <td>2765</td>\n",
       "      <td>1931</td>\n",
       "      <td>920</td>\n",
       "      <td>1764</td>\n",
       "      <td>228</td>\n",
       "      <td>1136</td>\n",
       "      <td>922</td>\n",
       "      <td>1309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20200518</td>\n",
       "      <td>3</td>\n",
       "      <td>40993</td>\n",
       "      <td>10137</td>\n",
       "      <td>780</td>\n",
       "      <td>2701</td>\n",
       "      <td>420</td>\n",
       "      <td>741</td>\n",
       "      <td>15544</td>\n",
       "      <td>532</td>\n",
       "      <td>...</td>\n",
       "      <td>326</td>\n",
       "      <td>1766</td>\n",
       "      <td>3320</td>\n",
       "      <td>2060</td>\n",
       "      <td>892</td>\n",
       "      <td>2447</td>\n",
       "      <td>337</td>\n",
       "      <td>1495</td>\n",
       "      <td>975</td>\n",
       "      <td>1912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20200518</td>\n",
       "      <td>4</td>\n",
       "      <td>77863</td>\n",
       "      <td>19603</td>\n",
       "      <td>1276</td>\n",
       "      <td>5019</td>\n",
       "      <td>968</td>\n",
       "      <td>1160</td>\n",
       "      <td>32101</td>\n",
       "      <td>968</td>\n",
       "      <td>...</td>\n",
       "      <td>669</td>\n",
       "      <td>2914</td>\n",
       "      <td>6986</td>\n",
       "      <td>3911</td>\n",
       "      <td>1368</td>\n",
       "      <td>4380</td>\n",
       "      <td>513</td>\n",
       "      <td>2940</td>\n",
       "      <td>1758</td>\n",
       "      <td>3629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>20200531</td>\n",
       "      <td>19</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>...</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>20200531</td>\n",
       "      <td>20</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>...</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>20200531</td>\n",
       "      <td>21</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>...</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>20200531</td>\n",
       "      <td>22</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>...</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>20200531</td>\n",
       "      <td>23</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>...</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>336 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           날짜  시간     10    100   101   120   121   140    150   160  ...  \\\n",
       "0    20200518   0  82065  15172  1500  3294  1086   962  28931  1103  ...   \n",
       "1    20200518   1  51248   9840   813  2356   696   546  17888   720  ...   \n",
       "2    20200518   2  39026   7894   760  2413   408   549  13357   498  ...   \n",
       "3    20200518   3  40993  10137   780  2701   420   741  15544   532  ...   \n",
       "4    20200518   4  77863  19603  1276  5019   968  1160  32101   968  ...   \n",
       "..        ...  ..    ...    ...   ...   ...   ...   ...    ...   ...  ...   \n",
       "331  20200531  19   -999   -999  -999  -999  -999  -999   -999  -999  ...   \n",
       "332  20200531  20   -999   -999  -999  -999  -999  -999   -999  -999  ...   \n",
       "333  20200531  21   -999   -999  -999  -999  -999  -999   -999  -999  ...   \n",
       "334  20200531  22   -999   -999  -999  -999  -999  -999   -999  -999  ...   \n",
       "335  20200531  23   -999   -999  -999  -999  -999  -999   -999  -999  ...   \n",
       "\n",
       "     1020  1040  1100  1200  1510  2510  3000  4510  5510  6000  \n",
       "0     618  2790  5147  4331  1329  3665   404  2242  1619  2314  \n",
       "1     430  1864  3269  2561   921  2081   272  1390  1003  1766  \n",
       "2     322  1313  2765  1931   920  1764   228  1136   922  1309  \n",
       "3     326  1766  3320  2060   892  2447   337  1495   975  1912  \n",
       "4     669  2914  6986  3911  1368  4380   513  2940  1758  3629  \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "331  -999  -999  -999  -999  -999  -999  -999  -999  -999  -999  \n",
       "332  -999  -999  -999  -999  -999  -999  -999  -999  -999  -999  \n",
       "333  -999  -999  -999  -999  -999  -999  -999  -999  -999  -999  \n",
       "334  -999  -999  -999  -999  -999  -999  -999  -999  -999  -999  \n",
       "335  -999  -999  -999  -999  -999  -999  -999  -999  -999  -999  \n",
       "\n",
       "[336 rows x 37 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(os.path.join(DATASET_PATH, 'test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "* 한 칼럼에 대한 7일(168행) 데이터를 input_data, 뒤따르는 7일 데이터를 output_data로 반환합니다.\n",
    "* 도로별 차이를 두지 않고 모든 도로를 동일한 타입의 데이터로 취급합니다.\n",
    "* 모든 csv 파일의 마지막 168행은 예측해야하는 값이므로 input으로 들어가지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(data.Dataset):      # torch.utils.data.Dataset 클래스의 상속 클래스 CustomDataset class 생성. 상속 클래스 생성시 __init__, __getitem__, __len__함수는 기본적으로 정의해줘야 함.\n",
    "    \n",
    "    def __init__(self, root, seq_len, batch_size=64, phase='train'):      # 데이터 로드 단계에 사용될 여러 변수들을 'self.변수명'의 형태로 지정해두는 함수\n",
    "        \n",
    "        self.root = root      # CustomDataset 객체 생성 시 데이터 경로 앞부분(공통 부분)을 root로 입력받아 저장\n",
    "        self.phase = phase      # CustomDataset 객체 생성 시 데이터 경로 뒷부분(train/validate/test)을 phase로 입력받아 저장\n",
    "        self.label_path = os.path.join(self.root, self.phase + '.csv')      # 데이터 전체 경로 생성\n",
    "        df = pd.read_csv(self.label_path)      # 생성한 데이터 전체 경로로부터 데이터 로드\n",
    "        \n",
    "        self.seq_len = seq_len * 24      # 일 단위 기간을 입력 받은 후 시간 단위 기간으로 변환하여 저장\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = {}\n",
    "        \n",
    "        timestamps = [(i, j) for (i, j) in zip(list(df['날짜']), list(df['시간']))]      # 날짜와 시간 정보가 튜플로 들어 있는 리스트 생성\n",
    "        categories = df.columns.values.tolist()[2:]      # 도로명 column list 생성\n",
    "\n",
    "        input_data = []\n",
    "        output_data = []\n",
    "\n",
    "        for t in range(len(timestamps)):\n",
    "            temp_input_data = []\n",
    "            temp_output_data = []\n",
    "            for col in categories:\n",
    "                road = df[col].tolist()\n",
    "                inp = [float(i) for i in road[t:t+self.seq_len]]      # input 데이터 시계열 구간 설정\n",
    "                outp = [float(j) for j in road[t+self.seq_len:t+2*self.seq_len]]      # output 데이터 시계열 구간 설정\n",
    "                temp_input_data.append(inp) \n",
    "                temp_output_data.append(outp)\n",
    "            input_data.append(temp_input_data)\n",
    "            output_data.append(temp_output_data)\n",
    "            \n",
    "# input_data : [[첫번째 input 기간 동안의 첫번째 도로의 통행량 list, ..., 첫번째 input 기간 동안의 35번째 도로의 통행량 list], ...,\n",
    "#               [마지막 input 기간 동안의 첫번째 도로의 통행량 list, ..., 마지막 input 기간 동안의 35번째 도로의 통행량 list]]\n",
    "# output_data : [[첫번째 output 기간 동안의 첫번째 도로의 통행량 list, ..., 첫번째 output 기간 동안의 35번째 도로의 통행량 list], ...,\n",
    "#                [마지막 output 기간 동안의 첫번째 도로의 통행량 list, ..., 마지막 output 기간 동안의 35번째 도로의 통행량 list]]\n",
    "        \n",
    "        self.labels['timestamp'] = timestamps\n",
    "        self.labels['category'] = categories\n",
    "        self.labels['input'] = input_data\n",
    "        self.labels['output'] = output_data\n",
    "\n",
    "    def __getitem__(self, index):      # index를 가지고 데이터를 하나씩 불러올 수 있게 하는 함수\n",
    "\n",
    "#         데이터 내 index가 부여되는 형태\n",
    "\n",
    "#                 | road_1    road_2    ...  road_35\n",
    "#                -------------------------------------\n",
    "#         time_1  | index_0   index_1   ...  index_34\n",
    "#         time_2  | index_35  index_36  ...  index_69\n",
    "\n",
    "        row = index // 35      # index를 35(도로수)로 나눈 몫  ex) 71//35 -> 2\n",
    "        col = index % 35      # index를 35(도로수)로 나눈 나머지  ex) 71%35 -> 1\n",
    "\n",
    "        timestamp = self.labels['timestamp'][row]      # (날짜, 시간) 튜플이 들어있는 list에서 row번째 시점에 해당하는 튜플\n",
    "        category = self.labels['category'][col]      # 도로명 column list에서 col번째 도로에 해당하는 element\n",
    "        \n",
    "        input_data = torch.tensor(self.labels['input'][row][col])      # input_data list에서, row번째 시점의 col번째 도로 교통량 정보\n",
    "\n",
    "        if self.phase != 'test':\n",
    "            output_data = torch.tensor(self.labels['output'][row][col])\n",
    "        else:\n",
    "            output_data = []\n",
    "\n",
    "        return timestamp, category, (input_data, output_data)\n",
    "\n",
    "    def __len__(self):      # getitem 함수를 통해 데이터를 불러오려면,전체 index 길이를 알아야 한다.\n",
    "        return (len(self.labels['timestamp']) - (self.seq_len * 2) + 1) * 35      # 특정 시점이 아닌 특정 기간을 하나의 data 단위로 설정하면, 전체 샘플 수는 감소함을 반영 \n",
    "\n",
    "\n",
    "def data_loader(root, phase='train', batch_size=64, seq_len=7, drop_last=False):\n",
    "    if phase == 'train':\n",
    "        shuffle = True\n",
    "    else:\n",
    "        shuffle = False\n",
    "\n",
    "    dataset = CustomDataset(root, seq_len, batch_size, phase)\n",
    "    dataloader = data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size=168,      # input 길이는 168시간(7일 X 24시간)\n",
    "                 hidden_size=1024,\n",
    "                 output_size=168,      # output 길이는 168시간(7일 X 24시간)\n",
    "                 batch_size=64,\n",
    "                 num_layers=3,\n",
    "                 dropout=0,\n",
    "                 batch_first=False):      # batch_first(default=False) : 배치 차원을 첫번째 차원으로 하여 데이터를 불러올 것인지 여부\n",
    "\n",
    "        super(LSTMNet, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        ##### Layer 1\n",
    "        self.lstm1 = nn.LSTM(input_size,\n",
    "                             hidden_size,\n",
    "                             dropout=0.2,\n",
    "                             num_layers=num_layers)\n",
    "\n",
    "        ##### Layer 2\n",
    "        self.lstm2 = nn.LSTM(hidden_size, \n",
    "                             hidden_size,\n",
    "                             dropout=0.2,\n",
    "                             num_layers=num_layers)\n",
    "\n",
    "        ##### Finalize\n",
    "        self.linear = nn.Linear(hidden_size, \n",
    "                                output_size)\n",
    "        \n",
    "        self.activation = nn.LeakyReLU(0.2)\n",
    "\n",
    "        \n",
    "    def forward(self, x, h_in, c_in):\n",
    "\n",
    "        h_in = nn.Parameter(h_in.type(dtype), requires_grad=True)      # gradient descent로 업데이트 되는(requires_grad=True), h_in 이라는 이름의 파라미터 생성 \n",
    "        c_in = nn.Parameter(c_in.type(dtype), requires_grad=True)      # gradient descent로 업데이트 되는(requires_grad=True), c_in 이라는 이름의 파라미터 생성\n",
    "\n",
    "        # Layer 1\n",
    "        lstm_out, (h_1, c_1) = self.lstm1(x, (h_in, c_in))\n",
    "        lstm_out = self.activation(lstm_out)\n",
    "\n",
    "        # Layer2\n",
    "        lstm_out, (h_2, c_2) = self.lstm2(lstm_out, (h_1, c_1))\n",
    "        lstm_out = self.activation(lstm_out)\n",
    "\n",
    "        # Final\n",
    "        predictions = self.linear(lstm_out)\n",
    "        \n",
    "        return predictions, (h_2, c_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 파일과 모델 가중치 파일 저장을 위해 log 디렉토리 생성. 중요한 파일이 덮어씌워지지 않도록 주의\n",
    "os.makedirs('log', exist_ok=True)\n",
    "\n",
    "\n",
    "def save_model(model_name, model, optimizer):\n",
    "    state = {\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(state, os.path.join('log', model_name + '.pth'))\n",
    "    print('model saved\\n')\n",
    "    return os.path.join('log', model_name + '.pth')\n",
    "\n",
    "\n",
    "def load_model(model_name, model, optimizer=None):\n",
    "    state = torch.load(os.path.join(model_name))\n",
    "    model.load_state_dict(state['model'])\n",
    "    if optimizer is not None:\n",
    "        optimizer.load_state_dict(state['optimizer'])\n",
    "    print('model loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "model_name = 'sequential'\n",
    "\n",
    "batch_size = 64\n",
    "num_epochs = 5\n",
    "val_epoch = 1\n",
    "base_lr = 0.01\n",
    "seq_len = 7\n",
    "\n",
    "input_size = seq_len * 24\n",
    "output_size = input_size\n",
    "hidden_size = 1024\n",
    "num_layers = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = LSTMNet(input_size=input_size,\n",
    "                hidden_size=hidden_size,\n",
    "                output_size=output_size,\n",
    "                batch_size=batch_size,\n",
    "                num_layers=num_layers)\n",
    "model = model.to(device)\n",
    "\n",
    "# loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = Adam(model.parameters(), lr=base_lr)      # optimizer로는 Adam이 가장 무난합니다. Adam을 쓰면 learning_rate를 따로 지정해주지 않아도 알아서 조정됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMNet(\n",
      "  (lstm1): LSTM(168, 1024, num_layers=6, dropout=0.2)\n",
      "  (lstm2): LSTM(1024, 1024, num_layers=6, dropout=0.2)\n",
      "  (linear): Linear(in_features=1024, out_features=168, bias=True)\n",
      "  (activation): LeakyReLU(negative_slope=0.2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get data loader\n",
    "train_dataloader = data_loader(root=DATASET_PATH,\n",
    "                               phase='train',\n",
    "                               batch_size=batch_size,\n",
    "                               seq_len=seq_len,\n",
    "                               drop_last=True)\n",
    "\n",
    "validate_dataloader = data_loader(root=DATASET_PATH,\n",
    "                                  phase='validate',\n",
    "                                  batch_size=1,\n",
    "                                  seq_len=seq_len,\n",
    "                                  drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:  0 | Batch:  400 | Loss: 3728980598.24\n",
      "Train Epoch:  0 | Batch:  800 | Loss: 3536669702.40\n",
      "Train Epoch:  0 | Batch: 1200 | Loss: 3583232043.36\n",
      "Train Epoch:  0 | Batch: 1600 | Loss: 3574298071.04\n",
      "\n",
      "Valid Epoch:  0 | Loss: 3657633076.29\n",
      "model saved\n",
      "\n",
      "Train Epoch:  1 | Batch:  400 | Loss: 3472009426.72\n",
      "Train Epoch:  1 | Batch:  800 | Loss: 3441433851.84\n",
      "Train Epoch:  1 | Batch: 1200 | Loss: 3317237148.16\n",
      "Train Epoch:  1 | Batch: 1600 | Loss: 3338890549.76\n",
      "\n",
      "Valid Epoch:  1 | Loss: 3429257056.69\n",
      "model saved\n",
      "\n",
      "Train Epoch:  2 | Batch:  400 | Loss: 3382783548.00\n",
      "Train Epoch:  2 | Batch:  800 | Loss: 3201032015.60\n",
      "Train Epoch:  2 | Batch: 1200 | Loss: 3128355178.88\n",
      "Train Epoch:  2 | Batch: 1600 | Loss: 3104603187.04\n",
      "\n",
      "Valid Epoch:  2 | Loss: 3242958532.80\n",
      "model saved\n",
      "\n",
      "Train Epoch:  3 | Batch:  400 | Loss: 3090788821.12\n",
      "Train Epoch:  3 | Batch:  800 | Loss: 3116822790.56\n",
      "Train Epoch:  3 | Batch: 1200 | Loss: 3046219253.60\n",
      "Train Epoch:  3 | Batch: 1600 | Loss: 2929375642.08\n",
      "\n",
      "Valid Epoch:  3 | Loss: 3103860902.06\n",
      "model saved\n",
      "\n",
      "Train Epoch:  4 | Batch:  400 | Loss: 3143394360.64\n",
      "Train Epoch:  4 | Batch:  800 | Loss: 2946171644.48\n",
      "Train Epoch:  4 | Batch: 1200 | Loss: 2779567142.40\n",
      "Train Epoch:  4 | Batch: 1600 | Loss: 2893502183.04\n",
      "\n",
      "Valid Epoch:  4 | Loss: 3009962306.06\n",
      "model saved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_batch_loss = 0.0\n",
    "train_epoch_loss = 0.0\n",
    "\n",
    "valid_epoch_loss = 0.0\n",
    "valid_min_epoch_loss = np.inf\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model.train()      # 모델을 train mode로 전환. train mode일 때만 적용되어야 하는 drop out 등이 적용될 수 있게 하기 위함 \n",
    "\n",
    "    for iter_, sample in enumerate(train_dataloader):      # enumerate 함수를 통해 train_dataloader에서 'batch의 index'와 'batch'를 순서대로 호출\n",
    "\n",
    "        (h_in, c_in) = (torch.zeros(num_layers, batch_size, hidden_size, requires_grad=True).to(device),\n",
    "                        torch.zeros(num_layers, batch_size, hidden_size, requires_grad=True).to(device))\n",
    "\n",
    "        _, _, (input_data, output_data) = sample      # train_dataloader에서 불러온 sample은 [[날짜, 시간], [도로], [[input_data],[output_data]]]로 구성됨. 학습에는 [[input_data], [output_data]]만 사용\n",
    "        \n",
    "        input_data = input_data.unsqueeze(0).to(device)\n",
    "        output_data = output_data.unsqueeze(0).to(device)\n",
    "\n",
    "        pred, (h_in, c_in) = model(input_data, h_in, c_in)\n",
    "        \n",
    "        loss = criterion(pred, output_data)\n",
    "\n",
    "        model.zero_grad()    # 파라미터 업데이트는 batch 단위로 이루어지고, 매 batch마다 gradient를 초기화해주어야 함 \n",
    "        loss.backward()      # backpropagation\n",
    "        optimizer.step()      # 파라미터 업데이트\n",
    "        \n",
    "        train_batch_loss += loss.item()\n",
    "        train_epoch_loss += loss.item()\n",
    "\n",
    "        if iter_ % 400 == 399:      # 400개의 batch마다 training Loss 출력\n",
    "            print('Train Epoch: {:2} | Batch: {:4} | Loss: {:1.2f}'.format(epoch, iter_+1, train_batch_loss/400))\n",
    "            train_batch_loss = 0\n",
    "            \n",
    "    train_epoch_loss = 0.0\n",
    "\n",
    "    \n",
    "    model.eval()      # 모델을 eval mode로 전환. eval mode에서 적용되면 안되는 drop out 등이 적용되지 않게 하기 위함\n",
    "\n",
    "    with torch.no_grad():      # validation / test set에 대해서는 weight 및 bias의 update, 즉, gradient descent가 일어나지 않도록 no_grad()를 선언\n",
    "        (h_in, c_in) = (torch.zeros(num_layers, 1, hidden_size, requires_grad=False).to(device),\n",
    "                        torch.zeros(num_layers, 1, hidden_size, requires_grad=False).to(device))\n",
    "\n",
    "        for iter_, sample in enumerate(validate_dataloader):      # enumerate 함수를 통해 validate_dataloader에서 'batch의 index'와 'batch'를 순서대로 호출\n",
    "\n",
    "            _, _, (input_data, output_data) = sample      # validate_dataloader에서 불러온 sample은 [[날짜, 시간], [도로], [[input_data],[output_data]]]로 구성됨. validation에는 [[input_data], [output_data]]만 사용\n",
    "\n",
    "            input_data = input_data.unsqueeze(0).to(device)\n",
    "            output_data = output_data.unsqueeze(0).to(device)\n",
    "\n",
    "            pred, (h_in, c_in) = model(input_data, h_in, c_in)\n",
    "            loss = criterion(pred, output_data)\n",
    "            valid_epoch_loss += loss.item()\n",
    "\n",
    "        print('\\nValid Epoch: {:2} | Loss: {:1.2f}'.format(epoch, valid_epoch_loss/len(validate_dataloader)))\n",
    "\n",
    "        if valid_epoch_loss < valid_min_epoch_loss:\n",
    "            save_model('best', model, optimizer)\n",
    "            valid_min_epoch_loss = valid_epoch_loss\n",
    "\n",
    "        valid_epoch_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "seq_len = 7\n",
    "\n",
    "input_size = seq_len * 24\n",
    "hidden_size = 1024\n",
    "output_size = input_size\n",
    "batch_size = 1\n",
    "num_layers = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = data_loader(root=DATASET_PATH,\n",
    "                              phase='test',\n",
    "                              batch_size=batch_size,\n",
    "                              seq_len=seq_len,\n",
    "                              drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "model = LSTMNet(input_size=input_size,\n",
    "                hidden_size=hidden_size,\n",
    "                output_size=output_size,\n",
    "                batch_size=batch_size,\n",
    "                num_layers=num_layers)\n",
    "\n",
    "# model\n",
    "model_name = 'log/best.pth'\n",
    "\n",
    "load_model(model_name, model)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file_path = os.path.join(DATASET_PATH, 'sample_submission.csv')\n",
    "submission_table = pd.read_csv(submission_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "(h_in, c_in) = (torch.zeros(num_layers, 1, hidden_size, requires_grad=False).to(device),\n",
    "                torch.zeros(num_layers, 1, hidden_size, requires_grad=False).to(device))\n",
    "\n",
    "for iter_, sample in enumerate(test_dataloader):\n",
    "\n",
    "    timestamp, category, (input_data, output_data) = sample\n",
    "    input_data = input_data.unsqueeze(0).to(device)\n",
    "\n",
    "    pred, (h_in, c_in) = model(input_data, h_in, c_in)\n",
    "\n",
    "    for i, (t, h) in enumerate(zip(timestamp[0], timestamp[1])):\n",
    "        for cat, row in zip(category, pred[0]):\n",
    "            cat = f'{cat}'\n",
    "            submission_table[cat] = row.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_table.to_csv('prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
